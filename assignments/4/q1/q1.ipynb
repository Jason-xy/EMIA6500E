{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('rainfall_summer_clim.csv')\n",
    "\n",
    "# Preprocess data: Map original labels to binary classification\n",
    "def label_mapping(x):\n",
    "    if x in [2, 3]:\n",
    "        return 'wet'\n",
    "    elif x in [0, 1]:\n",
    "        return 'not wet'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "data['Rainfall class'] = data['Rainfall class (0: < 0.5, 1: [0.5 4), 2: [4,8), 3: >= 8 (mm/day)'].apply(label_mapping)\n",
    "\n",
    "# Split data into features and target\n",
    "X = data[['Longitude (deg)', 'Latitude (deg)']]\n",
    "y = data['Rainfall class']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different kernels and class weight configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel: linear, Class Weight: None\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       962\n",
      "         wet       0.00      0.00      0.00       323\n",
      "\n",
      "    accuracy                           0.75      1285\n",
      "   macro avg       0.37      0.50      0.43      1285\n",
      "weighted avg       0.56      0.75      0.64      1285\n",
      "\n",
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "Kernel: linear, Class Weight: balanced\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.82      0.50      0.62       962\n",
      "         wet       0.31      0.68      0.43       323\n",
      "\n",
      "    accuracy                           0.55      1285\n",
      "   macro avg       0.57      0.59      0.53      1285\n",
      "weighted avg       0.70      0.55      0.57      1285\n",
      "\n",
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.79      0.53      0.63       414\n",
      "         wet       0.28      0.57      0.38       137\n",
      "\n",
      "    accuracy                           0.54       551\n",
      "   macro avg       0.54      0.55      0.51       551\n",
      "weighted avg       0.66      0.54      0.57       551\n",
      "\n",
      "\n",
      "Kernel: poly, Class Weight: None\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       962\n",
      "         wet       0.00      0.00      0.00       323\n",
      "\n",
      "    accuracy                           0.75      1285\n",
      "   macro avg       0.37      0.50      0.43      1285\n",
      "weighted avg       0.56      0.75      0.64      1285\n",
      "\n",
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "Kernel: poly, Class Weight: balanced\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.86      0.41      0.56       962\n",
      "         wet       0.32      0.81      0.45       323\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.59      0.61      0.51      1285\n",
      "weighted avg       0.73      0.51      0.53      1285\n",
      "\n",
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.85      0.37      0.52       414\n",
      "         wet       0.30      0.80      0.43       137\n",
      "\n",
      "    accuracy                           0.48       551\n",
      "   macro avg       0.57      0.59      0.47       551\n",
      "weighted avg       0.71      0.48      0.49       551\n",
      "\n",
      "\n",
      "Kernel: rbf, Class Weight: None\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.83      0.96      0.89       962\n",
      "         wet       0.78      0.39      0.52       323\n",
      "\n",
      "    accuracy                           0.82      1285\n",
      "   macro avg       0.80      0.68      0.71      1285\n",
      "weighted avg       0.82      0.82      0.80      1285\n",
      "\n",
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.82      0.96      0.88       414\n",
      "         wet       0.76      0.35      0.48       137\n",
      "\n",
      "    accuracy                           0.81       551\n",
      "   macro avg       0.79      0.66      0.68       551\n",
      "weighted avg       0.80      0.81      0.78       551\n",
      "\n",
      "\n",
      "Kernel: rbf, Class Weight: balanced\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.87      0.82      0.85       962\n",
      "         wet       0.55      0.64      0.59       323\n",
      "\n",
      "    accuracy                           0.78      1285\n",
      "   macro avg       0.71      0.73      0.72      1285\n",
      "weighted avg       0.79      0.78      0.78      1285\n",
      "\n",
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.86      0.81      0.83       414\n",
      "         wet       0.51      0.60      0.55       137\n",
      "\n",
      "    accuracy                           0.76       551\n",
      "   macro avg       0.69      0.71      0.69       551\n",
      "weighted avg       0.77      0.76      0.76       551\n",
      "\n",
      "\n",
      "Kernel: sigmoid, Class Weight: None\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.73      0.73      0.73       962\n",
      "         wet       0.19      0.18      0.18       323\n",
      "\n",
      "    accuracy                           0.60      1285\n",
      "   macro avg       0.46      0.46      0.46      1285\n",
      "weighted avg       0.59      0.60      0.59      1285\n",
      "\n",
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.72      0.74      0.73       414\n",
      "         wet       0.15      0.14      0.14       137\n",
      "\n",
      "    accuracy                           0.59       551\n",
      "   macro avg       0.43      0.44      0.44       551\n",
      "weighted avg       0.58      0.59      0.58       551\n",
      "\n",
      "\n",
      "Kernel: sigmoid, Class Weight: balanced\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.73      0.47      0.57       962\n",
      "         wet       0.23      0.47      0.31       323\n",
      "\n",
      "    accuracy                           0.47      1285\n",
      "   macro avg       0.48      0.47      0.44      1285\n",
      "weighted avg       0.60      0.47      0.51      1285\n",
      "\n",
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.68      0.47      0.56       414\n",
      "         wet       0.17      0.34      0.23       137\n",
      "\n",
      "    accuracy                           0.44       551\n",
      "   macro avg       0.43      0.40      0.39       551\n",
      "weighted avg       0.55      0.44      0.47       551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "class_weights = [None, 'balanced']\n",
    "\n",
    "for kernel in kernels:\n",
    "    for weight in class_weights:\n",
    "        print(f\"\\nKernel: {kernel}, Class Weight: {weight}\")\n",
    "        model = SVC(kernel=kernel, class_weight=weight)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "        print(\"Training Performance:\")\n",
    "        print(classification_report(y_train, y_pred_train, zero_division=0))\n",
    "        print(\"Test Performance:\")\n",
    "        print(classification_report(y_test, y_pred_test, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed analysis with RBF kernel and different C and gamma values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed RBF kernel analysis:\n",
      "\n",
      "C: 100, Gamma: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.85      0.95      0.90       414\n",
      "         wet       0.76      0.50      0.60       137\n",
      "\n",
      "    accuracy                           0.83       551\n",
      "   macro avg       0.80      0.72      0.75       551\n",
      "weighted avg       0.83      0.83      0.82       551\n",
      "\n",
      "\n",
      "C: 100, Gamma: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.82      0.96      0.89       414\n",
      "         wet       0.75      0.38      0.50       137\n",
      "\n",
      "    accuracy                           0.81       551\n",
      "   macro avg       0.79      0.67      0.70       551\n",
      "weighted avg       0.81      0.81      0.79       551\n",
      "\n",
      "\n",
      "C: 100, Gamma: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "C: 30, Gamma: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.83      0.96      0.89       414\n",
      "         wet       0.77      0.40      0.53       137\n",
      "\n",
      "    accuracy                           0.82       551\n",
      "   macro avg       0.80      0.68      0.71       551\n",
      "weighted avg       0.82      0.82      0.80       551\n",
      "\n",
      "\n",
      "C: 30, Gamma: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.83      0.96      0.89       414\n",
      "         wet       0.75      0.39      0.52       137\n",
      "\n",
      "    accuracy                           0.82       551\n",
      "   macro avg       0.79      0.68      0.70       551\n",
      "weighted avg       0.81      0.82      0.79       551\n",
      "\n",
      "\n",
      "C: 30, Gamma: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "C: 10, Gamma: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.82      0.97      0.89       414\n",
      "         wet       0.80      0.36      0.49       137\n",
      "\n",
      "    accuracy                           0.82       551\n",
      "   macro avg       0.81      0.66      0.69       551\n",
      "weighted avg       0.82      0.82      0.79       551\n",
      "\n",
      "\n",
      "C: 10, Gamma: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "C: 10, Gamma: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "C: 3, Gamma: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.82      0.96      0.88       414\n",
      "         wet       0.76      0.35      0.48       137\n",
      "\n",
      "    accuracy                           0.81       551\n",
      "   macro avg       0.79      0.66      0.68       551\n",
      "weighted avg       0.80      0.81      0.78       551\n",
      "\n",
      "\n",
      "C: 3, Gamma: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "C: 3, Gamma: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "C: 1, Gamma: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.82      0.96      0.88       414\n",
      "         wet       0.76      0.35      0.48       137\n",
      "\n",
      "    accuracy                           0.81       551\n",
      "   macro avg       0.79      0.66      0.68       551\n",
      "weighted avg       0.80      0.81      0.78       551\n",
      "\n",
      "\n",
      "C: 1, Gamma: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n",
      "\n",
      "C: 1, Gamma: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not wet       0.75      1.00      0.86       414\n",
      "         wet       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.75       551\n",
      "   macro avg       0.38      0.50      0.43       551\n",
      "weighted avg       0.56      0.75      0.64       551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDetailed RBF kernel analysis:\")\n",
    "C_values = [100, 30, 10, 3, 1]\n",
    "gamma_values = [0.5, 0.1, 0.05]\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        print(f\"\\nC: {C}, Gamma: {gamma}\")\n",
    "        model = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "        print(classification_report(y_test, y_pred_test, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emia6500",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

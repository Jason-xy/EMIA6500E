{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Noisy Training Data\n",
    "- We will build a neural net (nn) to fit a quadratic function.  \n",
    "- We will first generate some noisy training data to simulate real-world data.  \n",
    "- NNs are noise-resistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42) # For reproducibility\n",
    "x = np.linspace(-10, 10, 100000)\n",
    "a, b, c = 2, 3, -1 # True parameters. We will try to recover these parameters\n",
    "# True model + noise. \n",
    "y = a * x ** 2 + b * x + c + np.random.normal(0, 1, len(x)) \n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# split train, val, test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(x_train, y_train)\n",
    "val_dataset = MyDataset(x_val, y_val)\n",
    "test_dataset = MyDataset(x_test, y_test)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "A neural network with only 3 learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetQuadratic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetQuadratic, self).__init__()\n",
    "        # learnable parameters\n",
    "        self._a = nn.Parameter(torch.randn(1))\n",
    "        self._b = nn.Parameter(torch.randn(1))\n",
    "        self._c = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._a * x ** 2 + self._b * x + self._c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NetQuadratic()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "LR=1e-3 # Learning rate\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "TOTAL_EPOCHS = 100\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    for i, (x_batch, y_batch) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = net(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}/{TOTAL_EPOCHS}, Train Loss: {loss.item()}')\n",
    "\n",
    "        # validation loss\n",
    "        with torch.no_grad():\n",
    "            avg_val_loss = 0\n",
    "            for x_val_batch, y_val_batch in val_dataloader:\n",
    "                y_val_pred = net(x_val_batch)\n",
    "                val_loss = criterion(y_val_pred, y_val_batch)\n",
    "                avg_val_loss += val_loss.item()\n",
    "            avg_val_loss /= len(val_dataloader)\n",
    "            print(f'Epoch {epoch}/{TOTAL_EPOCHS}, Val Loss: {avg_val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "# Test\n",
    "with torch.no_grad():\n",
    "    avg_test_loss = 0\n",
    "    for x_test_batch, y_test_batch in test_dataloader:\n",
    "        y_test_pred = net(x_test_batch)\n",
    "        test_loss = criterion(y_test_pred, y_test_batch)\n",
    "        avg_test_loss += test_loss.item()\n",
    "    avg_test_loss /= len(test_dataloader)\n",
    "    print(f'Test Loss: {avg_test_loss}')\n",
    "\n",
    "# Print learned parameters\n",
    "error = (net._a.item()-a)**2 + (net._b.item()-b)**2 + (net._c.item()-c)**2\n",
    "print(f'Learned a: {net._a.item()}, b: {net._b.item()}, c: {net._c.item()}')\n",
    "print(f'True a: {a}, b: {b}, c: {c}')\n",
    "print(\"error: \", error)\n",
    "\n",
    "if error < 1e-3:\n",
    "    print(\"Success! Your model has converged to the true parameters.\")\n",
    "else:\n",
    "    raise ValueError(\"Failed! The error is too large.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the training set\n",
    "import matplotlib.pyplot as plt\n",
    "# plot name\n",
    "plt.title('Training set')\n",
    "plt.scatter(x_train, y_train, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the learned model\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_pred = net(x_tensor)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "plt.plot(x, y_pred, color='red')\n",
    "plt.title('Learned model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d2cfb1e010eacc9d1833061fead5992395503aef0fba5ffab510ab5f37dcdc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
